# CS1470 Final Project: Outline

### Title
Detect fakes from the dataset containing real images and CNN-generated images.

### Who
Jovan Kemp (jkemp1), Kei Yoshida (kyoshid1)

### Introduction
- We will implement an existing paper (Wang et al., 2020) that created a “universal” detector to identify fake images generated by 11 different CNN-based models. They showed that a classifier (ResNet-50) trained on only one CNN generator (ProGAN) is generalizable to other architectures. We chose this paper because **???**.
- This is a classification problem that categorizes image datasets into real and CNN-generated images.

### Related Work
- **Cozzolino et al., 2018**
    - Similar to Wang et al. (2020), this paper explores a method to detect fake images under cross-model transfer. However, instead of focusing on simple classifiers that can be used for different models (Wang et al.), they propose a new learning method, called rensicTransfer (FT), that improves the performance.
- **Karras et al., 2020**
    - **???**
- Deep Residual Learning for Image Recognition
    - **???**
- Public implementations (we haven't found any so far but will add as we find them.)

### Data
- We first plan to use the dataset provided by Wang et al. (2020) at the initial stage of the project. They performed careful preprocessing operations and data augmentation, and we expect it to be difficult to perform the same operations. After we implement the system in TensorFlow (originally PyTorch), we will attempt to generate our own dataset and apply the model, using free image datasets such as https://imerit.net/blog/22-free-image-datasets-for-computer-vision-all-pbm/. We hope to increase the data diversity, as Wang et al.(2020) argue that image diversity improves performance.
- The original dataset contains a total of ~72k images generated by 11 different models (ProGAN, StyleGAN, BigGAN, CycleGAN, StarGAN, GauGAN, CRN, IMLE, SITD, SAN, FaceForensics++). The number of classes varied between 2-20 classes.  When we generate our own dataset, we will need to do some preprocessing (e.g., changing resolution), as well as data augmentation while training (e.g., Gaussian blue, JPEG).

### Methodology
- With the dataset used by Wang et al. (2020), we will train the universal detector (ResNet-50) on ProGAN dataset. Post-processing is operated in a variety of ways during training; all images will be left-right flipped and cropped to 224x224 pixels. In addition, they will be augmented with Gaussian blur and/or JPEG, as Wang et al.(2020) claimed that augmentation improves generalization and robustness. We will use ResNet-50 pre-trained with ImageNet, and train it for binary classification (i.e., whether an image is real or fake). After we establish the system, we will implement the same system with our own dataset.
- We anticipate that **???** will be the hardest part about our implementation.

### Metrics
- **Experiments**: **???**
- Accuracy applies to our project. Each image in the dataset is either real of fake, so we can determine the test accuracy after training. Specifically, the original paper computed and compared average precision (AP) for each of the 11 generation models. We will implement the same method in our project.
- Wang et al. (2020) hoped to find that a model trained on one specific dataset can be generalized when tested on other datasets. They assessed generalizability using AP while varying the number of classes and augmentation methods; they compared AP for different models and variations.
- **Base goal**: **???**
- **Target goal**: **???**
- **Stretch goal**: **???**

### Ethics
- What broader societal issues are relevant to your chosen problem space?
    - As deep image synthesis technology advances, people are more worried about whether they are able to tell real and fake images apart. This issue is significant as the technology can be used for malicious purposes, such as manipulating global politics, identity theft, and tarnishing the reputation of someone. The original paper used a video of the president of Gabon as an example; he made an appearance in a video of which the opposition questioned the legitimacy, and this led to an unsuccessful coup d’etat.
- Why is Deep Learning a good approach to this problem?
    - Although it may be possible to identify images produced by deep fake networks and GANS using other approaches, it would be difficult to produce a detector which is generalizable to many instantiations of image manipulating networks. The authors claim that popular image manipulating networks leave behind a learnable trace that a simple convolutional neural network trained from ResNet can detect.

### Division of Labor
- Jovan: Obtain Train/Test Images, Run images through GAN
- Kei: Train/Test Images, **???**

### References
- Cozzolino, D., Thies, J., Rössler, A., Riess, C., Nießner, M., & Verdoliva, L. (2018). Forensictransfer: Weakly-supervised domain adaptation for forgery detection. *arXiv preprint arXiv:1812.02510*. https://arxiv.org/pdf/1812.02510.pdf
- Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., & Aila, T. (2020). Analyzing and improving the image quality of stylegan. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 8110-8119). https://openaccess.thecvf.com/content_CVPR_2020/papers/Karras_Analyzing_and_Improving_the_Image_Quality_of_StyleGAN_CVPR_2020_paper.pdf
- Wang, S. Y., Wang, O., Zhang, R., Owens, A., & Efros, A. A. (2020). CNN-generated images are surprisingly easy to spot... for now. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 8695-8704). https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_CNN-Generated_Images_Are_Surprisingly_Easy_to_Spot..._for_Now_CVPR_2020_paper.pdf
