# CS1470 Final Project: Outline

### Title
Detect fakes from the dataset containing real images and CNN-generated images.

### Who
Jovan Kemp (jkemp1), Kei Yoshida (kyoshid1)

### Introduction
- We will implement an existing paper (Wang et al., 2020) that created a “universal” detector to identify fake images generated by 11 different CNN-based models. They showed that a classifier (ResNet-50) trained on only one CNN generator (ProGAN) is generalizable to other architectures. We chose this paper because **???**.
- This is a classification problem that categorizes image datasets into real and CNN-generated images.

### Related Work
- **Cozzolino et al., 2018**
    - Similar to Wang et al. (2020), this paper explores a method to detect fake images under cross-model transfer. However, instead of focusing on simple classifiers that can be used for different models (Wang et al.), they propose a new learning method, called rensicTransfer (FT), that improves the performance.
- Deep Residual Learning for Image Recognition (He, Zhang, Ren, & Sun, 2015)
    - This project developed the Res Net which forms the bases for the current project. It proposes a new neural network model for training very deep networks using learning residual functions. They show around a 28% improvement on a 1000 class classification task using deep layers that are efficiently trained.
- Public implementations (we haven't found any so far but will add as we find them.)

### Data
- We first plan to use the dataset provided by Wang et al. (2020) at the initial stage of the project. They performed careful preprocessing operations and data augmentation, and we expect it to be difficult to perform the same operations. After we implement the system in TensorFlow (originally PyTorch), we will attempt to generate our own dataset and apply the model, using free image datasets such as https://imerit.net/blog/22-free-image-datasets-for-computer-vision-all-pbm/. We hope to increase the data diversity, as Wang et al.(2020) argue that image diversity improves performance.
- The original dataset contains a total of ~72k images generated by 11 different models (ProGAN, StyleGAN, BigGAN, CycleGAN, StarGAN, GauGAN, CRN, IMLE, SITD, SAN, FaceForensics++). The number of classes varied between 2-20 classes.  When we generate our own dataset, we will need to do some preprocessing (e.g., changing resolution), as well as data augmentation while training (e.g., Gaussian blue, JPEG).

### Methodology
- With the dataset used by Wang et al. (2020), we will train the universal detector (ResNet-50) on ProGAN dataset. Post-processing is operated in a variety of ways during training; all images will be left-right flipped and cropped to 224x224 pixels. In addition, they will be augmented with Gaussian blur and/or JPEG, as Wang et al.(2020) claimed that augmentation improves generalization and robustness. We will use ResNet-50 pre-trained with ImageNet along with additional framework created by the authors, and train it for binary classification (i.e., whether an image is real or fake). After we establish the system, we will implement the same system with our own dataset.
- We anticipate that transferring the weights to meet the base goal and training base ResNet to meet the target goal will be the hardest part about our implementation.

### Metrics
- Experiments: We plan to test the model on generative networks that were not used for training along with images taken from deep fake videos. The later test set is important given the increased number of CNN produced fake videos that are appearing on the internet.
- Accuracy applies to our project. Each image in the dataset is either real of fake, so we can determine the test accuracy after training. Specifically, the original paper computed and compared average precision (AP) for each of the 11 generation models. We will implement the same method in our project.
- Wang et al. (2020) hoped to find that a model trained on one specific dataset can be generalized when tested on other datasets. They assessed generalizability using AP while varying the number of classes and augmentation methods; they compared AP for different models and variations.
- **Base goal**: Recode the network from pytorch into tensorflow, import the weights (requires data structure conversion) and obtain benchmarks set by the paper
- **Target goal**: Train the base ResNet with additional framework on provided train and evaluate with test set. Use images taken from deep fake videos for additional evaluation
- **Stretch goal**: Produce new training set using a new generative model not listed in paper and conduct same evaluation procedure. Add additional framework to improve scores cited in paper

### Ethics
- What broader societal issues are relevant to your chosen problem space?
    - As deep image synthesis technology advances, people are more worried about whether they are able to tell real and fake images apart. This issue is significant as the technology can be used for malicious purposes, such as manipulating global politics, identity theft, and tarnishing the reputation of someone. The original paper used a video of the president of Gabon as an example; he made an appearance in a video of which the opposition questioned the legitimacy, and this led to an unsuccessful coup d’etat.
- Why is Deep Learning a good approach to this problem?
    - Although it may be possible to identify images produced by deep fake networks and GANS using other approaches, it would be difficult to produce a detector which is generalizable to many instantiations of image manipulating networks. The authors claim that popular image manipulating networks leave behind a learnable trace that a simple convolutional neural network trained from ResNet can detect.

### Division of Labor
- Jovan: transcribe from pytorch to tensorflow, test project model, develop new train/test set
- Kei: transfer weights from pytorch to tensorflow, train new model for target goal, develop new train/test set

### References
- Cozzolino, D., Thies, J., Rössler, A., Riess, C., Nießner, M., & Verdoliva, L. (2018). Forensictransfer: Weakly-supervised domain adaptation for forgery detection. *arXiv preprint arXiv:1812.02510*. https://arxiv.org/pdf/1812.02510.pdf
- Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., & Aila, T. (2020). Analyzing and improving the image quality of stylegan. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 8110-8119). https://openaccess.thecvf.com/content_CVPR_2020/papers/Karras_Analyzing_and_Improving_the_Image_Quality_of_StyleGAN_CVPR_2020_paper.pdf
- Wang, S. Y., Wang, O., Zhang, R., Owens, A., & Efros, A. A. (2020). CNN-generated images are surprisingly easy to spot... for now. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 8695-8704). https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_CNN-Generated_Images_Are_Surprisingly_Easy_to_Spot..._for_Now_CVPR_2020_paper.pdf

